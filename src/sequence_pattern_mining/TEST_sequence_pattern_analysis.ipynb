{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import data_analyser\n",
    "import copy\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../data')\n",
    "data = data_analyser.DataAnalyser('article_sample.csv').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['item_name', 'user_name', 'comment_simplified']]\n",
    "grouped = df.groupby(['item_name', 'user_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Created a list of itemlists\n",
    "\"\"\"\n",
    "def createSequences(grouped_data):\n",
    "    sequences = []\n",
    "    for name, group in grouped_data:\n",
    "        event = []\n",
    "        for user in grouped.get_group(name)['user_name']:\n",
    "            activity = grouped.get_group(name)['comment_simplified'].unique().tolist()\n",
    "            event.append(activity)\n",
    "        sequences.append(event)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a simple recursive method that checks if subsequence is a subSequence of mainSequence\n",
    "\"\"\"\n",
    "def isSubsequence(mainSequence, subSequence):\n",
    "    subSequenceClone = list(subSequence) # clone the sequence, because we will alter it\n",
    "    return isSubsequenceRecursive(mainSequence, subSequenceClone) #start recursion\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function for the recursive call of isSubsequence, not intended for external calls\n",
    "\"\"\"\n",
    "def isSubsequenceRecursive(mainSequence, subSequenceClone, start=0):\n",
    "    # Check if empty: End of recursion, all itemsets have been found\n",
    "    if (not subSequenceClone):\n",
    "        return True\n",
    "    # retrieves element of the subsequence and removes is from subsequence \n",
    "    firstElem = set(subSequenceClone.pop(0))\n",
    "    # Search for the first itemset...\n",
    "    for i in range(start, len(mainSequence)):\n",
    "        if (set(mainSequence[i]).issuperset(firstElem)):\n",
    "            # and recurse\n",
    "            return isSubsequenceRecursive(mainSequence, subSequenceClone, i + 1)\n",
    "    return False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Computes the length of the sequence (sum of the length of the contained itemsets)\n",
    "\"\"\"\n",
    "def sequenceLength(sequence):\n",
    "    return sum(len(i) for i in sequence)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Computes the support of a sequence in a dataset\n",
    "\"\"\"\n",
    "def countSupport (dataset, candidateSequence):\n",
    "    return sum(1 for seq in dataset if isSubsequence(seq, candidateSequence)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates one candidate of length k from two candidates of length (k-1) as used in the AprioriAll algorithm\n",
    "\"\"\"\n",
    "def generateCandidatesForPair(cand1, cand2):\n",
    "    cand1Clone = copy.deepcopy(cand1)\n",
    "    cand2Clone = copy.deepcopy(cand2)\n",
    "    # drop the leftmost item from cand1:\n",
    "    if (len (cand1[0]) == 1):\n",
    "        cand1Clone.pop(0)\n",
    "    else:\n",
    "        cand1Clone[0] = cand1Clone[0][1:]\n",
    "    # drop the rightmost item from cand2:\n",
    "    if (len (cand2[-1]) == 1):\n",
    "        cand2Clone.pop(-1)\n",
    "    else:\n",
    "        cand2Clone[-1] = cand2Clone[-1][:-1]\n",
    "    \n",
    "    # if the result is not the same, then we dont need to join\n",
    "    if not cand1Clone == cand2Clone:\n",
    "        return []\n",
    "    else:\n",
    "        newCandidate = copy.deepcopy(cand1)\n",
    "        if (len (cand2[-1]) == 1):\n",
    "            newCandidate.append(cand2[-1])\n",
    "        else:\n",
    "            newCandidate [-1].extend(cand2[-1][-1])\n",
    "        return newCandidate\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Generates the set of candidates of length k from the set of frequent sequences with length (k-1)\n",
    "\"\"\"\n",
    "def generateCandidates(lastLevelCandidates):\n",
    "    k = sequenceLength(lastLevelCandidates[0]) + 1\n",
    "    if (k == 2):\n",
    "        flatShortCandidates = [item for sublist2 in lastLevelCandidates for sublist1 in sublist2 for item in sublist1]\n",
    "        result = [[[a, b]] for a in flatShortCandidates for b in flatShortCandidates if b > a]\n",
    "        result.extend([[[a], [b]] for a in flatShortCandidates for b in flatShortCandidates])\n",
    "        return result\n",
    "    else:\n",
    "        candidates = []\n",
    "        for i in range(0, len(lastLevelCandidates)):\n",
    "            for j in range(0, len(lastLevelCandidates)):\n",
    "                newCand = generateCandidatesForPair(lastLevelCandidates[i], lastLevelCandidates[j])\n",
    "                if (not newCand == []):\n",
    "                    candidates.append(newCand)\n",
    "        candidates.sort()\n",
    "        return candidates\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Computes all direct subsequence for a given sequence.\n",
    "A direct subsequence is any sequence that originates from deleting exactly one item from any event in the original sequence.\n",
    "\"\"\"\n",
    "def generateDirectSubsequences(sequence):\n",
    "    result = []\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if (len(itemset) == 1):\n",
    "            sequenceClone = copy.deepcopy(sequence)\n",
    "            sequenceClone.pop(i)\n",
    "            result.append(sequenceClone)\n",
    "        else:\n",
    "            for j in range(len(itemset)):\n",
    "                sequenceClone = copy.deepcopy(sequence)\n",
    "                sequenceClone[i].pop(j)\n",
    "                result.append(sequenceClone)\n",
    "    return result\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Prunes the set of candidates generated for length k given all frequent sequence of level (k-1), as done in AprioriAll\n",
    "\"\"\"\n",
    "def pruneCandidates(candidatesLastLevel, candidatesGenerated):\n",
    "    return [cand for cand in candidatesGenerated if all(x in candidatesLastLevel for x in generateDirectSubsequences(cand))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The AprioriAll algorithm. Computes the frequent sequences in a seqeunce dataset for a given minSupport\n",
    "\n",
    "Args:\n",
    "    dataset: A list of sequences, for which the frequent (sub-)sequences are computed\n",
    "    minSupport: The minimum support that makes a sequence frequent\n",
    "    verbose: If true, additional information on the mining process is printed (i.e., candidates on each level)\n",
    "Returns:\n",
    "    A list of tuples (s, c), where s is a frequent sequence, and c is the count for that sequence\n",
    "\"\"\"\n",
    "def apriori(dataset, minSupport, verbose=False):\n",
    "    global numberOfCountingOperations\n",
    "    numberOfCountingOperations = 0\n",
    "    Overall = []\n",
    "    itemsInDataset = sorted(set ([item for sublist1 in dataset for sublist2 in sublist1 for item in sublist2]))\n",
    "    singleItemSequences = [[[item]] for item in itemsInDataset]\n",
    "    singleItemCounts = [(i, countSupport(dataset, i)) for i in singleItemSequences if countSupport(dataset, i) >= minSupport]\n",
    "    Overall.append(singleItemCounts)\n",
    "    print (\"Result, lvl 1: \" + str(Overall[0]))\n",
    "    k = 1\n",
    "    while (True):\n",
    "        if not Overall [k - 1]:\n",
    "            break\n",
    "        # 1. Candidate generation\n",
    "        candidatesLastLevel = [x[0] for x in Overall[k - 1]]\n",
    "        candidatesGenerated = generateCandidates (candidatesLastLevel)\n",
    "        # 2. Candidate pruning (using a \"containsall\" subsequences)\n",
    "        candidatesPruned = [cand for cand in candidatesGenerated if all(x in candidatesLastLevel for x in generateDirectSubsequences(cand))]\n",
    "        # 3. Candidate checking\n",
    "        candidatesCounts = [(i, countSupport(dataset, i)) for i in candidatesPruned]\n",
    "        resultLvl = [(i, count) for (i, count) in candidatesCounts if (count >= minSupport)]\n",
    "        Overall.append(resultLvl)\n",
    "        k = k + 1\n",
    "    # \"flatten\" Overall\n",
    "    Overall = Overall [:-1]\n",
    "    Overall = [item for sublist in Overall for item in sublist]\n",
    "    return Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result, lvl 1: [([['']], 1096), ([['Created page']], 252), ([['Restored edits']], 310), ([['Reverted edits']], 701), ([['Undo']], 959), ([['clientsitelink-remove']], 344), ([['clientsitelink-update']], 2050), ([['wbcreateclaim']], 185), ([['wbcreateclaim-create']], 7636), ([['wbcreateredirect']], 83), ([['wbeditentity']], 92), ([['wbeditentity-create']], 50), ([['wbeditentity-override']], 43), ([['wbeditentity-update']], 3459), ([['wbmergeitems']], 483), ([['wbremoveclaims']], 40), ([['wbremoveclaims-remove']], 2109), ([['wbremovequalifiers-remove']], 45), ([['wbremovereferences-remove']], 84), ([['wbsetaliases-add']], 2319), ([['wbsetaliases-add-remove']], 744), ([['wbsetaliases-remove']], 244), ([['wbsetaliases-set']], 299), ([['wbsetaliases-update']], 108), ([['wbsetclaim-create']], 5072), ([['wbsetclaim-update']], 2855), ([['wbsetclaim-update-qualifiers']], 233), ([['wbsetclaim-update-rank']], 22), ([['wbsetclaimvalue']], 81), ([['wbsetdescription-add']], 4124), ([['wbsetdescription-remove']], 78), ([['wbsetdescription-set']], 5078), ([['wbsetentity']], 695), ([['wbsetlabel-add']], 1571), ([['wbsetlabel-remove']], 286), ([['wbsetlabel-set']], 3714), ([['wbsetlabeldescriptionaliases']], 122), ([['wbsetqualifier-add']], 1129), ([['wbsetreference']], 543), ([['wbsetreference-add']], 3248), ([['wbsetreference-set']], 79), ([['wbsetsitelink-add']], 4628), ([['wbsetsitelink-remove']], 477), ([['wbsetsitelink-set']], 2531), ([['wbsetsitelink-set-both']], 209)]\n"
     ]
    }
   ],
   "source": [
    "dataset = createSequences(grouped)\n",
    "apriori(dataset, 20, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
